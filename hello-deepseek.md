---
title: "你好Deepseek"
date: 2025-02-11T11:31:18+08:00
draft: false
---

过年期间科技圈最大的新闻莫过于 deepseek 的发布了，其最大的特点就是训练成本低，但是效果非常好。距离 openai 发布 chatgpt 已经过去了两年，期间 google, meta 等公司发布的模型都是类似的效果，不像这次效果这么惊艳。

但我大致看了下相关的介绍文章，deepseek 依然没有原理上的突破，只能说是工程上的优化。

学习也看了不少的文章：
[科普文1](https://magazine.sebastianraschka.com/p/understanding-reasoning-llms "understanding reasoning llms")
[科普文2](https://writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work/ "What Is ChatGPT Doing … and Why Does It Work?")

李宏毅讲解的视频还没看完，刚刚看到开头。

这次技术进步和以往有一个很大的不同，就是普通人参与难度增加了。以往都说计算机系学习知识比较简单，一根网线一台电脑就够。大模型时代就不成立了，哪怕是微调，可能也需要很贵的设备，租用云服务那就是按秒计费了。

泛泛地看看科普文章，其实学不到什么东西，这个东西的原理性东西还没研究明白，只能是看谁试验做得快。

计算机界又回到以前凿壁偷光的时代了。
