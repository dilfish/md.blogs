---
title: "机器学习复习"
date: 2020-06-25T14:26:24+08:00
draft: false
---

As we will see later, the  𝐿2  loss corresponds to the assumption that our data was corrupted by Gaussian noise, whereas the  𝐿1  loss corresponds to an assumption of noise from a Laplace distribution.

pytorch 里面的 broadcast 功能，如果是 3x2 + 2x1 则如何?

参考资料：[理解矩阵](https://blog.csdn.net/myan/article/details/647511)

a vector norm is a function  𝑓  that maps a vector to a scalar,



参考资料 [向量微积分系列](https://betterexplained.com/articles/vector-calculus-understanding-the-dot-product/)

https://blog.csdn.net/u010976453/article/details/54381248
https://www.cnblogs.com/pinard/p/10791506.html

参考[分布估计](https://towardsdatascience.com/estimating-distributions-nonparametric-713ccf0647b)

## 随机变量
随机变量实际上是一个函数。在表示时，一般使用 X。又如 X(x) 则表示函数 X 的 x 参数。或者 X = 1 则表示函数X的值是1的是时候。

## 多维度
维度上升时，计算积在数值上逐渐减少直到0。不同维度的积没有比较的意义。
