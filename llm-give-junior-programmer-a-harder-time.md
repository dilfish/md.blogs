---
title: "AI 让初级程序员更难了"
date: 2025-09-24T18:07:06+08:00
draft: false
---

最近有一个说法，是说大模型 AI 的出现，延缓了大龄程序员被裁的风险，而让初级程序员的就业更加困难了。如果这个说法正确的话，我想理由可能是这样的：初级程序员相对大龄程序员最显著的优势就是体力好，能加班。对于技术含量并不那么高的项目来说，快就是好，多就是好。大模型的出现改变了这个情况，大模型产出更高，但是可靠性又没那么高，所以需要的是一个导师，教练的角色，在这个角色上显然大龄程序员更具优势。

我今天看到一个文章，也可以显示出大模型带来的变化：[From Rust to Reality: The Hidden Journey of fetch_max](https://questdb.com/blog/rust-fetch-max-compiler-journey/)。这个文章抽丝剥茧一样分析了 rust 的 fetch_max 的实现。从语言层面，到编译器层面，再到 CPU 层面。

传统上这需要非常强大的能力，首先你对 rust 语言要有一定程度的熟悉，对于高级特性例如 macro，如果没学习过，还需要比较笼统地学习一次。接下来对 llvm 项目也要有相当程度的了解，起码知道各个模块的功能和对应的代码的分布，最好是也熟悉 llvm 的中间语言 ir，满足这个条件的话，要找到具体某个函数的实现也不是那么容易，要花费一些时间。最后到了汇编阶段，还需要对于汇编语言有一定程度的了解，如果出现了陌生的指令，学习新指令又要花费一点时间。

我们看到这里的需求是两方面，一方面是能力的需求，例如对于 rust 语言的了解，对于 llvm 项目的了解，对于汇编语言的了解，对于 CPU 的了解。如果你写文章之前不够熟悉的话，现学肯定是来不及了，在没学会之前，你根本没有可能写出这样的文章。

另一方面也有一些体力活的需求，例如 rust 具体函数具体指令的学习，llvm 具体 ir 语句的学习，具体 CPU 指令的学习，这部分学习虽然难度比较低，但是花费时间也相当客观，是一个比较耗时的体力活。

大模型出现之后，一切都变了。我们可以假设大模型是了解所有项目的所有指令的，在需要的时候实时问就可以，这将节省大量的时间，所以不再有体力活了。对于第一部分能力的需求，也浓缩到一个更高层级的抽象能力中。也就是说，你不需要熟悉任何一种语言，只需要熟悉一种抽象的编程语言理论即可。对于 CPU 和 llvm 也是类似的，需要学习的是 CPU 理论和编译器理论，而不需要了解具体的 ARM CPU 或者 llvm 项目。

既然大模型这么优秀，那能不能连抽象的知识也不需要，只要一句话就写出这样的文章呢？现在还是不能。

因为大模型 AI 不是为可靠设计的，所以在一个逻辑链条中，每一步都需要一个导师或者教练来确认，如果任由它自己发挥，那么一个微小的错误将会导致后续的流程全部错误了。

所以这也显示出了初学者的困境：如果不经过大量的体力活，具体项目的训练，你不太能有足够的判断力。但是现在大模型自己就垄断了体力活，训练的过程对于公司来说没有价值了。再一个困难的地方在于，如果没有具体的项目的训练，初学者可能也无法分解这个任务。

所以大模型的出现，确实给程序员带来了更高的要求，产业界不再需要体力活的训练，你在学校的时候，就要学会更高层次抽象的理论知识，学会提问，学会验证。而具体项目或者具体产品的知识在提问大模型的过程中知道就足够了，处理完任务之后，你甚至应该忘记这个具体的知识。
